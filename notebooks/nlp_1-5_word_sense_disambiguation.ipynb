{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_1-5_word_sense_disambiguation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgPmSJ95ix2q"
      },
      "source": [
        "# **Word Sense Disambiguation**\n",
        "\n",
        "Words can have different meanings in different contexts. Sometimes the intended\n",
        "meaning of a word is hard to understand and leads to miscommunication. If a word has multiple meanings, this is called word\n",
        "sense ambiguity. While solving syntactic ambiguity is done with part-of-speech (POS)\n",
        "tagging, solving semantic ambiguity is done with word sense disambiguation (WSD).\n",
        "The challenge is to semantically separate words by their meaning in context [[1]](#scrollTo=fPge5oRLQwid).\n",
        "\n",
        "This notebook shows examples of WSD with the ``pywsd`` library."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "45TfUvkfi9QU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install pywsd\n",
        "\n",
        "``pywsd`` is a Python library that provides WSD functions as well as several variations of the Lesk algorithm [[1]](#scrollTo=fPge5oRLQwid). For more details about ``pywsd``, please refer to [[2]](https://pypi.org/project/pywsd/).\n",
        "\n"
      ],
      "metadata": {
        "id": "_csm4xc0R-_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pywsd\n",
        "!pip install pywsd  "
      ],
      "metadata": {
        "id": "4_feI89HA9Pg",
        "outputId": "d32a8a27-67f5-4605-fe06-63031c96db60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pywsd\n",
            "  Downloading pywsd-1.2.4.tar.gz (26.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.8 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pywsd) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.3.5)\n",
            "Collecting wn\n",
            "  Downloading wn-0.9.1-py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2022.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (4.1.1)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (1.24.3)\n",
            "Building wheels for collected packages: pywsd\n",
            "  Building wheel for pywsd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pywsd: filename=pywsd-1.2.4-py3-none-any.whl size=26940436 sha256=82fb480a489a5ebe5593773cdc2fe97c0068bbfc38fbc3a324b3fd7254dc59db\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/67/c0/6e6fa8456d1374b393328368316c3b33844cb4043bd225bc66\n",
            "Successfully built pywsd\n",
            "Installing collected packages: wn, pywsd\n",
            "Successfully installed pywsd-1.2.4 wn-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install ``wn``\n",
        "``wn`` is a new Python library for working with wordnets. Unlike previous libraries, ``wn`` is built from the beginning to accommodate multiple wordnets (for multiple languages or multiple versions of the same wordnet) while retaining the ability to query and traverse them independently. For more detail about the ``wn`` library, please refer to [[3]](https://pypi.org/project/wn/) and [[4]](https://aclanthology.org/2021.gwc-1.12/).\n",
        "\n"
      ],
      "metadata": {
        "id": "FpGN8eXeSFxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install wn\n",
        "!pip install wn==0.0.22"
      ],
      "metadata": {
        "id": "YmpRgxijC8oV",
        "outputId": "5142a989-d0ed-40e6-fd08-6e382c38054e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wn==0.0.22\n",
            "  Downloading wn-0.0.22.tar.gz (31.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.5 MB 1.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wn\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.22-py3-none-any.whl size=31618484 sha256=dd4dddd129974f1683520f474e625f021e87ccc440ebc0edbf7a3276804b5608\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/0d/59/4b7902879d8cbad9bb73aaf0cc0a051edc1b18da983889c412\n",
            "Successfully built wn\n",
            "Installing collected packages: wn\n",
            "  Attempting uninstall: wn\n",
            "    Found existing installation: wn 0.9.1\n",
            "    Uninstalling wn-0.9.1:\n",
            "      Successfully uninstalled wn-0.9.1\n",
            "Successfully installed wn-0.0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import ``nltk`` and ``wordnet``\n",
        "\n",
        "``nltk``(Natural Language Toolkit) is an open source Python library for natural language processing. For more details about ``nltk``, please refer to [[5]](https://www.nltk.org/api/nltk.html#nltk.wsd.lesk).\n",
        "\n",
        "``wordnet`` is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms, each expressing a distinct concept. Synonyms are interlinked by means of conceptual-semantic and lexical relations [[6]](http://www.nltk.org/howto/wsd.html). \n"
      ],
      "metadata": {
        "id": "GdGgQWKKUQok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the nltk module\n",
        "import nltk\n",
        "\n",
        "# Download \"wordnet\" package by using the nltk module\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# The module \"averaged_perceptron_tagger\" is used for POS tagging\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# The module \"punkt\" is used for tokenizing sentences \n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download 'omw-1.4' to use Multilingual Wordnet Data from OMW with newer Wordnet versions (December 2021 release)\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "B4Hqv8tCMMf3",
        "outputId": "dd9e1ed2-d868-4a6b-aca6-ec5191503597",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import ``simple_lesk``\n",
        "\n",
        "The ``lesk`` algorithm is an example of a knowledge-based method and is based on contextual overlap of dictionary definitions. The approach is based on the assumption that words used together are also related to each other [[1]](#scrollTo=fPge5oRLQwid)."
      ],
      "metadata": {
        "id": "FHkuushxUcNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the simple_lesk algorithm\n",
        "from pywsd.lesk import simple_lesk  "
      ],
      "metadata": {
        "id": "n2hi79CYBEi1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WSD application examples"
      ],
      "metadata": {
        "id": "7HwviBLLjCIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bank"
      ],
      "metadata": {
        "id": "G2gPMfkNWI8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample text which contains two sentences\n",
        "text1 = ['I went to the bank to deposit my money', 'The river bank was full of dead fishes']\n",
        "\n",
        "# Analyze the first sentence and print the definition of the word \"bank\"\n",
        "print( \"=============== Analyze sentence 1 =================\\n\")\n",
        "print (\"Context-1:\", text1[0])  \n",
        "answer1 = simple_lesk(text1[0],'bank')  \n",
        "print (\"Sense:\", answer1)  \n",
        "print (\"Definition: \", answer1.definition())  \n",
        "\n",
        "# Analyze the second sentence and print the definition of the word \"bank\"\n",
        "print( \"\\n\\n=============== Analyze sentence 2 =================\\n\")\n",
        "print (\"Context-2:\", text1[1])  \n",
        "answer2 = simple_lesk(text1[1],'bank')  \n",
        "print (\"Sense:\", answer2)  \n",
        "print (\"Definition: \", answer2.definition())  \n",
        "\n",
        "# For a general overview, print all definitions of the word \"bank\"\n",
        "print( \"\\n\\n=============== All definitions of the word \\'bank\\'===============\\n\")\n",
        "for s in wn.synsets('bank'):\n",
        "    print('\\t', s, s.definition())"
      ],
      "metadata": {
        "id": "IW471hbAMjJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46dc2f8e-1a8e-474f-b454-7d37f3d8ff20"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== Analyze sentence 1 =================\n",
            "\n",
            "Context-1: I went to the bank to deposit my money\n",
            "Sense: Synset('depository_financial_institution.n.01')\n",
            "Definition:  a financial institution that accepts deposits and channels the money into lending activities\n",
            "\n",
            "\n",
            "=============== Analyze sentence 2 =================\n",
            "\n",
            "Context-2: The river bank was full of dead fishes\n",
            "Sense: Synset('bank.n.01')\n",
            "Definition:  sloping land (especially the slope beside a body of water)\n",
            "\n",
            "\n",
            "=============== All definitions of the word 'bank'===============\n",
            "\n",
            "\t Synset('bank.n.01') sloping land (especially the slope beside a body of water)\n",
            "\t Synset('depository_financial_institution.n.01') a financial institution that accepts deposits and channels the money into lending activities\n",
            "\t Synset('bank.n.03') a long ridge or pile\n",
            "\t Synset('bank.n.04') an arrangement of similar objects in a row or in tiers\n",
            "\t Synset('bank.n.05') a supply or stock held in reserve for future use (especially in emergencies)\n",
            "\t Synset('bank.n.06') the funds held by a gambling house or the dealer in some gambling games\n",
            "\t Synset('bank.n.07') a slope in the turn of a road or track; the outside is higher than the inside in order to reduce the effects of centrifugal force\n",
            "\t Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n",
            "\t Synset('bank.n.09') a building in which the business of banking transacted\n",
            "\t Synset('bank.n.10') a flight maneuver; aircraft tips laterally about its longitudinal axis (especially in turning)\n",
            "\t Synset('bank.v.01') tip laterally\n",
            "\t Synset('bank.v.02') enclose with a bank\n",
            "\t Synset('bank.v.03') do business with a bank or keep an account at a bank\n",
            "\t Synset('bank.v.04') act as the banker in a game or in gambling\n",
            "\t Synset('bank.v.05') be in the banking business\n",
            "\t Synset('deposit.v.02') put into a bank account\n",
            "\t Synset('bank.v.07') cover with ashes so to control the rate of burning\n",
            "\t Synset('trust.v.01') have confidence or faith in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plant"
      ],
      "metadata": {
        "id": "6AD2Aw6uYB1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample text which contains two sentences\n",
        "text2 = ['The workers at the industrial plant were overworked.', 'The plant was no longer bearing flowers.']\n",
        "\n",
        "# Analyze the first sentence and print the definition of the word \"plant\"\n",
        "print( \"=============== Analyze sentence 1 =================\\n\")\n",
        "print (\"Context-1:\", text2[0])  \n",
        "answer1 = simple_lesk(text2[0],'plant')  \n",
        "print (\"Sense:\", answer1)  \n",
        "print (\"Definition: \", answer1.definition())  \n",
        "\n",
        "# Analyze the second sentence and print the definition of the word \"plant\"\n",
        "print( \"\\n\\n=============== Analyze sentence 2 =================\\n\")\n",
        "print (\"Context-2:\", text2[1])  \n",
        "answer2 = simple_lesk(text2[1],'plant')  \n",
        "print (\"Sense:\", answer2)  \n",
        "print (\"Definition: \", answer2.definition())  \n",
        "\n",
        "# For a general overview, print all definitions of the word \"plant\"\n",
        "print( \"\\n\\n=============== All definitions of the word \\'plant\\'===============\\n\")\n",
        "for s in wn.synsets('plant'):\n",
        "    print('\\t', s, s.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrAM723hYImV",
        "outputId": "802e2c3a-476e-4f72-d59d-07c5ffc22c0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== Analyze sentence 1 =================\n",
            "\n",
            "Context-1: The workers at the industrial plant were overworked.\n",
            "Sense: Synset('plant.n.01')\n",
            "Definition:  buildings for carrying on industrial labor\n",
            "\n",
            "\n",
            "=============== Analyze sentence 2 =================\n",
            "\n",
            "Context-2: The plant was no longer bearing flowers.\n",
            "Sense: Synset('plant.v.01')\n",
            "Definition:  put or set (seeds, seedlings, or plants) into the ground\n",
            "\n",
            "\n",
            "=============== All definitions of the word 'plant'===============\n",
            "\n",
            "\t Synset('plant.n.01') buildings for carrying on industrial labor\n",
            "\t Synset('plant.n.02') (botany) a living organism lacking the power of locomotion\n",
            "\t Synset('plant.n.03') an actor situated in the audience whose acting is rehearsed but seems spontaneous to the audience\n",
            "\t Synset('plant.n.04') something planted secretly for discovery by another\n",
            "\t Synset('plant.v.01') put or set (seeds, seedlings, or plants) into the ground\n",
            "\t Synset('implant.v.01') fix or set securely or deeply\n",
            "\t Synset('establish.v.02') set up or lay the groundwork for\n",
            "\t Synset('plant.v.04') place into a river\n",
            "\t Synset('plant.v.05') place something or someone in a certain position in order to secretly observe or deceive\n",
            "\t Synset('plant.v.06') put firmly in the mind\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fair"
      ],
      "metadata": {
        "id": "d7T1C_OuYFKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample text which contains two sentences\n",
        "text3 = ['Everyone needs to be given a fair chance in the competition.', 'The annual fair in our city is next weekend.']\n",
        "\n",
        "# Analyze the first sentence and print the definition of the word \"fair\"\n",
        "print( \"=============== Analyze sentence 1 =================\\n\")\n",
        "print (\"Context-1:\", text3[0])  \n",
        "answer1 = simple_lesk(text3[0],'fair')  \n",
        "print (\"Sense:\", answer1)  \n",
        "print (\"Definition : \", answer1.definition())  \n",
        "\n",
        "# Analyze the second sentence and print the definition of the word \"fair\"\n",
        "print( \"\\n\\n=============== Analyze sentence 2 =================\\n\")\n",
        "print (\"Context-2:\", text3[1])  \n",
        "answer2 = simple_lesk(text3[1],'fair', 'n')  \n",
        "print (\"Sense:\", answer2)  \n",
        "print (\"Definition : \", answer2.definition())  \n",
        "\n",
        "# For a general overview, print all definitions of the word \"fair\"\n",
        "print( \"\\n\\n=============== All definitions of the word \\'fair\\'===============\\n\")\n",
        "for s in wn.synsets('fair'):\n",
        "    print('\\t', s, s.definition())"
      ],
      "metadata": {
        "id": "WhjZ7MPJYJOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5ffd08-bc28-4d69-de24-9409a175ad39"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== Analyze sentence 1 =================\n",
            "\n",
            "Context-1: Everyone needs to be given a fair chance in the competition.\n",
            "Sense: Synset('honest.s.07')\n",
            "Definition :  gained or earned without cheating or stealing\n",
            "\n",
            "\n",
            "=============== Analyze sentence 2 =================\n",
            "\n",
            "Context-2: The annual fair in our city is next weekend.\n",
            "Sense: Synset('fair.n.03')\n",
            "Definition :  a competitive exhibition of farm products\n",
            "\n",
            "\n",
            "=============== All definitions of the word 'fair'===============\n",
            "\n",
            "\t Synset('carnival.n.03') a traveling show; having sideshows and rides and games of skill etc.\n",
            "\t Synset('fair.n.02') gathering of producers to promote business\n",
            "\t Synset('fair.n.03') a competitive exhibition of farm products\n",
            "\t Synset('bazaar.n.03') a sale of miscellany; often for charity\n",
            "\t Synset('fair.v.01') join so that the external surfaces blend smoothly\n",
            "\t Synset('fair.a.01') free from favoritism or self-interest or bias or deception; conforming with established standards or rules\n",
            "\t Synset('fair.a.04') (of a baseball) hit between the foul lines\n",
            "\t Synset('fair.s.02') not excessive or extreme\n",
            "\t Synset('bonny.s.01') very pleasing to the eye\n",
            "\t Synset('average.s.03') lacking exceptional quality or ability\n",
            "\t Synset('fair.s.06') attractively feminine\n",
            "\t Synset('clean.s.11') (of a manuscript) having few alterations or corrections\n",
            "\t Synset('honest.s.07') gained or earned without cheating or stealing\n",
            "\t Synset('fair.s.09') free of clouds or rain\n",
            "\t Synset('fair.s.10') (used of hair or skin) pale or light-colored\n",
            "\t Synset('fairly.r.03') in conformity with the rules or laws and without fraud or cheating\n",
            "\t Synset('fairly.r.02') without favoring one party, in a fair evenhanded manner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References**\n",
        "\n",
        "- [1] Course Book \"NLP and Computer Vision\" (DLMAINLPCV01)\n",
        "- [2] https://pypi.org/project/pywsd/\n",
        "- [3] https://pypi.org/project/wn/\n",
        "- [4] https://aclanthology.org/2021.gwc-1.12/\n",
        "- [5] https://www.nltk.org/api/nltk.html#nltk.wsd.lesk\n",
        "- [6] http://www.nltk.org/howto/wsd.html\n",
        "\n"
      ],
      "metadata": {
        "id": "fPge5oRLQwid"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHARdTvlix3T"
      },
      "source": [
        "Copyright © 2022 IU International University of Applied Sciences"
      ]
    }
  ]
}
